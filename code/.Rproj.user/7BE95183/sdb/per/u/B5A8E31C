{
    "contents" : "#Nested logit coding assignment\n# Coded by Pantelis Loupos & Richard Zhiji Xu\n\nsource('header.R')\n\n#load data\nsetwd(\"C:/Users/D11xzj/Desktop/OPNS_NestedLogit-master/variables\")\nlambda<-readRDS(\"lambda_values.rds\")\nval<-readRDS(\"choice_values.rds\")\n\n#Generate the Gumbles up front\nn=10000; # number of repetitions to simulate\ne<-matrix(rgev(n*3,xi=0,mu=0,beta=1),nrow=3) #The first row gives the 10000 e1, etc\nh<-array(rgev(n*9,xi=0,mu=0,beta=1),dim=c(3,3,n)) #Similarly, but now we have 9 items\n\n#Converting the data frames into vectors/matrix\nlambdas<- lambda[,2]\nV<-matrix(val[,3], nrow=3, ncol=3, byrow=TRUE)\n\n# Below is the one-shot simulation\nU<-array(0,dim=c(3,3,n))\nfor (m in 1:n){\n  for (k in 1:3){\n    for (i in 1:3){\n      U[i,k,m]<-V[i,k]+e[k,m]+lambdas[k]*h[i,k,m]\n    }}}\n\nchoice2<-array(0,dim=n)\nfor (m in 1:n){\n  choice2[m]<-which.max(U[,,m])\n}\n\n# convert the choice vector into a data frame\nchoice2.m<-array(0,dim=c(2,n))\nchoice2.m[1,] = (choice2-1) %/% 3 + 1\nchoice2.m[2,] = (choice2) %% 3\nchoice2.m[2,] = replace(choice2.m[2,], choice2.m[2,]==0, 3)\n\nchoice2.d=data.frame(choice=choice2.m[2,])\nchoice2.d$bucket=choice2.m[1,]\n\n# compute the choice probabilities\npr2<- table(choice2.d) /10000\n\n# Sequential simulation\nchoice1.m<-array(0,dim=c(2,n))\nfor (m in 1:n)\n{\n  IV <- lambdas*log(rowSums(matrix(exp((as.vector(t(V))+rep(e[,m],times=3))/rep(lambdas,times=3)),ncol=3)))\n  choice1.m[1,m]<-which.max(IV)\n  util=V[,choice1.m[1,m]]+lambdas[choice1.m[1,m]]*h[,choice1.m[1,m],m]\n  choice1.m[2,m]=which.max(util)\n}\n\n#convert the choice matrix into a vector\nchoice1=(choice1.m[1,]-1)*3+choice1.m[2,]\n\n# convert the choice matrix into a data frame\nchoice1.d=data.frame(choice=choice1.m[2,])\nchoice1.d$bucket=choice1.m[1,]\n\n# compute the choice probabilities\npr1 <- table(choice1.d)/n\n\n# Bootstrap\nNumBS <- 100\n\n# For the sequential case\nprob1 <- array(0,dim=c(NumBS,9)) # for recording the probability vectors\n\ntemp.m<-array(0,dim=c(2,n)) # for converting the choice vector into a data frame\n\nfor (ite in 1:NumBS){\n  temp.choice1 <- sample(choice1,n,replace=TRUE) # we use the sample command for sampling with repetition\n  # convert the choice vector into a data frame\n  temp.m[1,] = (temp.choice1-1) %/% 3 + 1\n  temp.m[2,] = (temp.choice1) %% 3\n  temp.m[2,] = replace(temp.m[2,], temp.m[2,]==0, 3)\n  temp.d=data.frame(bucket=temp.m[1,])\n  temp.d$choice=temp.m[2,]\n  # record the probability vector\n  prob1[ite,] = as.vector(table(temp.d)/n)\n}\n\n# Compute the mean and covariance\nmean.prob1<-matrix(colMeans(prob1),nrow=3,byrow=TRUE)\ncov.prob1<-cov(prob1)\n\n# For the one-shot case\nprob2 <- array(0,dim=c(NumBS,9)) # for recording the probability vectors\n\ntemp.m<-array(0,dim=c(2,n)) # for converting the choice vector into a data frame\n\nfor (ite in 1:NumBS){\n  temp.choice2 <- sample(choice2,n,replace=TRUE)\n  # convert the choice vector into a data frame\n  temp.m[1,] = (temp.choice2-1) %/% 3 + 1\n  temp.m[2,] = (temp.choice2) %% 3\n  temp.m[2,] = replace(temp.m[2,], temp.m[2,]==0, 3)\n  temp.d=data.frame(bucket=temp.m[1,])\n  temp.d$choice=temp.m[2,]\n  # record the probability vector\n  prob2[ite,] = as.vector(table(temp.d)/n)\n}\n\n# Compute the mean and covariance\nmean.prob2<-matrix(colMeans(prob2),nrow=3,byrow=TRUE)\ncov.prob2<-cov(prob2)\n\n# Part 5: Wald Test\n\n# Compute the theoretical values\n# Compute the IV for each of the three buckets\nIV_theory=array(0,dim=3)\nfor (k in 1:3){\n  IV_theory[k]=lambdas[k]*log(exp(V[1,k]/lambdas[k])+exp(V[2,k]/lambdas[k])+exp(V[3,k]/lambdas[k]))\n}\n# Compute the probability of each bucket\nbucket_prob= exp(IV_theory) / sum(exp(IV_theory))\n# Compute the probability of each choice\nprob_theory=array(0,dim=c(3,3))\nfor (i in 1:3){\n  for (k in 1:3){\n    prob_theory[i,k]= bucket_prob[k] * (exp(V[i,k]/lambdas[k]) / (exp(V[1,k]/lambdas[k])+exp(V[2,k]/lambdas[k])+exp(V[3,k]/lambdas[k])))\n  }\n}\n\n# Wald Test\n# For sequential case\ndiff1 = as.vector(t(mean.prob1)) - as.vector(t(prob_theory))\nstat1 = t(diff1) %*% ginv(cov.prob1) %*% diff1\n1-pchisq(stat1,8) # p-value\n# The Wald test results indicate that we can't reject the null hypothesis that the choice probability estimates in the sequential specification are equal to the theoretical values for the sequential specification.\n\n# For one-shot case\ndiff2 = as.vector(t(mean.prob2)) - as.vector(t(prob_theory))\nstat2 = t(diff2) %*% ginv(cov.prob2) %*% diff2\n1-pchisq(stat2,8) # p-value\n\n# The Wald test results indicate that we can reject the null hypothesis that the choice probability estimates in the single-shot specification are equal to the theoretical values for the sequential specification.\n\n# We tried to derive a theoretical probability vector for the one-shot specification, but we didn't figure it out.\n\n# Reflection: Our programming style is more old-fashioned. We read the codes from Kejia, and we appreciate the more clear way of using \"sapply\" instead of \"for\", etc. (But for some reason, our codes run faster?!) We will improve our vectorized coding.\n",
    "created" : 1414469962218.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "2461687357",
    "id" : "B5A8E31C",
    "lastKnownWriteTime" : 140598217469184,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}